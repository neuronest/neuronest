name: object_detection

on:
#  push:
#    branches:
#      - main
#      - develop
#    paths:
#      - .github/workflows/object_detection.yaml
#      - .github/actions/**
#      - .github/variables/**
#      - .pre-commit-config.yaml
#      - shared/**
#      - object-detection/**
#  pull_request:
#    branches:
#      - main
#      - develop
#    paths:
#      - .github/workflows/object_detection.yaml
#      - .github/actions/**
#      - .github/variables/**
#      - .pre-commit-config.yaml
#      - shared/**
#      - object-detection/**
#  workflow_dispatch:
  workflow_call:
    inputs:
      build:
        required: false
        type: string
        default: 'true'
      deploy:
        required: false
        type: string
        default: 'true'
      do_post_deployment:
        required: false
        type: string
        default: 'true'
      env_file_artifact_name:
        required: false
        type: string
        default: ''
      base_project_builder_sa_key:
        required: false
        type: string
        default: ""
      dockerhub_training_image_name:
        required: false
        type: string
        default: ""
      gcp_training_image_name:
        required: false
        type: string
        default: ""
      model_instantiator_url:
        required: false
        type: string
        default: ""
    outputs:
      gcp_training_image_name:
        description: "The gcp training image name"
        value: ${{ jobs.get_gcp_training_image_name.outputs.value }}
      dockerhub_training_image_name:
        description: "The dockerhub training image name"
        value: ${{ jobs.get_dockerhub_training_image_name.outputs.value }}
      base_project_builder_sa_key:
        description: 'The base64 encoded key of the IAC service account of the shared repository'
        value: ${{ jobs.get_base_project_builder_sa_key.outputs.value }}

env:
  REPOSITORY_NAME: object-detection

jobs:
  run_base_terraform:
    runs-on: ubuntu-latest
    if: ${{ (inputs.deploy == 'true' || inputs.deploy == '')  && !failure() }}
    container: google/cloud-sdk
    outputs:
      base_project_builder_sa_key: ${{ steps.run_base_terraform.outputs.base_project_builder_sa_key }}
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/set_variables_gcloud_auth
        with:
          credentials_json: ${{ secrets.NEURONEST_INFRASTRUCTURE_BUILDER_SERVICE_ACCOUNT }}
          env_file_artifact_name: ${{ inputs.env_file_artifact_name }}
      - id: run_base_terraform
        uses: ./.github/actions/run_base_terraform

  build_test_push_training_image:
    name: build_test_push_training_image
    runs-on: ubuntu-latest
    needs: run_base_terraform
    if: ${{ (inputs.build == 'true' || inputs.build == '') && !failure() }}
    container: google/cloud-sdk
    outputs:
      dockerhub_training_image_name: ${{ steps.build_test_push.outputs.dockerhub_image_name }}
      gcp_training_image_name: ${{ steps.build_test_push.outputs.gcp_image_name }}
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/set_variables_gcloud_auth
        with:
          credentials_json: ${{ secrets.NEURONEST_INFRASTRUCTURE_BUILDER_SERVICE_ACCOUNT }}
          env_file_artifact_name: ${{ inputs.env_file_artifact_name }}
      - id: build_test_push
        uses: ./.github/actions/build_test_push
        with:
          dockerhub_username: ${{ vars.DOCKERHUB_USERNAME }}
          dockerhub_password: ${{ secrets.DOCKERHUB_PASSWORD }}
          target: training

  get_gcp_training_image_name:
    runs-on: ubuntu-latest
    needs: build_test_push_training_image
    if: ${{ !failure() }}
    outputs:
      value: ${{ steps.get_gcp_training_image_name.outputs.gcp_training_image_name }}
    steps:
      - id: get_gcp_training_image_name
        run: |
          job_gcp_training_image_name=${{ needs.build_test_push_training_image.outputs.gcp_training_image_name }}
          input_gcp_training_image_name=${{ inputs.gcp_training_image_name }}
          gcp_training_image_name=${job_gcp_training_image_name:-$input_gcp_training_image_name}
          echo "gcp_training_image_name=$gcp_training_image_name" | tee -a $GITHUB_OUTPUT

  get_dockerhub_training_image_name:
    runs-on: ubuntu-latest
    needs: build_test_push_training_image
    if: ${{ !failure() }}
    outputs:
      value: ${{ steps.get_dockerhub_training_image_name.outputs.dockerhub_training_image_name }}
    steps:
      - id: get_dockerhub_training_image_name
        run: |
          job_dockerhub_training_image_name=${{ needs.build_test_push_training_image.outputs.dockerhub_training_image_name }}
          input_dockerhub_training_image_name=${{ inputs.dockerhub_training_image_name }}
          dockerhub_training_image_name=${job_dockerhub_training_image_name:-$input_dockerhub_training_image_name}
          echo "dockerhub_training_image_name=$dockerhub_training_image_name" | tee -a $GITHUB_OUTPUT

  deploy_with_training_image:
    name: deploy_with_training_image
    runs-on: ubuntu-latest
    needs: get_dockerhub_training_image_name
    # the documentation specifies that if only one job is skipped
    # in a series of jobs dependencies defined by the "needs: ", all subsequent jobs are
    # skipped. To allow jobs to run despite a skip in the series,
    # we use the !failure() condition
    # see: https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idneeds
    if: ${{ (inputs.deploy == 'true' || inputs.deploy == '') && !failure() }}
    container: google/cloud-sdk
    outputs:
      base_project_builder_sa_key: ${{ steps.base_run_terraform.outputs.base_project_builder_sa_key }}
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/set_variables_gcloud_auth
        with:
          credentials_json: ${{ secrets.NEURONEST_INFRASTRUCTURE_BUILDER_SERVICE_ACCOUNT }}
          env_file_artifact_name: ${{ inputs.env_file_artifact_name }}
      - id: base_run_terraform
        uses: ./.github/actions/run_base_terraform
      - uses: ./.github/actions/run_terraform
        with:
          targets: ${{ env.MAIN_TERRAFORM_RESOURCES }}
          workspace: ${{ env.REPOSITORY_NAME }}
          image_name: ${{ needs.get_dockerhub_training_image_name.outputs.value }}

  get_base_project_builder_sa_key:
    runs-on: ubuntu-latest
    needs: deploy_with_training_image
    if: ${{ !failure() }}
    outputs:
      value: ${{ steps.get_base_project_builder_sa_key.outputs.base_project_builder_sa_key }}
    steps:
      - id: get_base_project_builder_sa_key
        run: |
          job_base_project_builder_sa_key=${{ needs.deploy_with_training_image.outputs.base_project_builder_sa_key }}
          input_base_project_builder_sa_key=${{ inputs.base_project_builder_sa_key }}
          # take the one that is not empty
          base_project_builder_sa_key=${job_base_project_builder_sa_key:-$input_base_project_builder_sa_key}
          echo "base_project_builder_sa_key=$base_project_builder_sa_key" | tee -a $GITHUB_OUTPUT

  train:
    name: train
    needs:
      - get_gcp_training_image_name
      - get_dockerhub_training_image_name
      - get_base_project_builder_sa_key
    runs-on: ubuntu-latest
    if: ${{ (inputs.do_post_deployment == 'true' || inputs.do_post_deployment == '') && !failure() }}
    defaults:
      run:
        working-directory: ${{ env.REPOSITORY_NAME }}
    container:
      image: ${{needs.get_dockerhub_training_image_name.outputs.value}}
      credentials:
        username: ${{ vars.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_PASSWORD }}
    env:
      # todo: sans doute changer le model/model.pt hardcodé, on n'a pas de raison de
      # penser que cette valeur sera toujours la bonne. Le directory model est obtenu
      # via une variable d'environnement dans un environnement vertex et qui pourra
      # changer. La partie "model" du filename est une valeur par défaut du script
      # python, tout comme l'extension ".pt" qui est une valeur par défaut
      # Il suffit que vertex ou le code python ou les arguments du code python changent
      # pour que "model/model.pt" ne fonctionne plus, il vaudrait mieux trouver $
      # dynamiquement le path du model post training
      # exemple :
      #   model_gspath=$(gsutil ls -r "gs://${MODELS_BUCKET}/${PACKAGE_NAME}-${{ github.sha }}/**/*.pt")
      MODEL_WEIGHTS: model/model.pt
    outputs:
      model_gspath: ${{ steps.output_step.outputs.model_gspath }}
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/set_variables_gcloud_auth
        with:
          credentials_json: ${{ needs.get_base_project_builder_sa_key.outputs.value }}
          env_file_artifact_name: ${{ inputs.env_file_artifact_name }}
      - id: set_additional_variables
        run: |
          echo "MODEL_GSPATH"="gs://${MODELS_BUCKET}/${PACKAGE_NAME}-${{ github.sha }}" | tee -a $GITHUB_ENV
      - id: train
        run: |
          python -m object_detection.cli --model-gspath $MODEL_GSPATH --actions train
        env:
          TRAINING_IMAGE_NAME: ${{ needs.get_gcp_training_image_name.outputs.value }}
          SERVICE_ACCOUNT_EMAIL: ${{ env.PROJECT_BUILDER_SERVICE_ACCOUNT_EMAIL }}
      # todo: il y a sûrement un premier problème de naming à corriger ici :
      # model_gspath qui devient {model_gspath}/{$model_weights} ça ne parait pas
      # logique.
      - id: output_step
        run: echo "model_gspath=$MODEL_GSPATH/$MODEL_WEIGHTS" | tee -a $GITHUB_OUTPUT

  build_test_push_serving_image:
    name: build_test_push_serving_image
    needs:
      - get_base_project_builder_sa_key
      - train
    runs-on: ubuntu-latest
    if: ${{ (inputs.do_post_deployment == 'true' || inputs.do_post_deployment == '') && !failure() }}
    container: google/cloud-sdk
    outputs:
      dockerhub_serving_image_name: ${{ steps.build_test_push.outputs.dockerhub_image_name }}
      gcp_serving_image_name: ${{ steps.build_test_push.outputs.gcp_image_name }}
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/set_variables_gcloud_auth
        with:
          credentials_json: ${{ needs.get_base_project_builder_sa_key.outputs.value }}
          env_file_artifact_name: ${{ inputs.env_file_artifact_name }}
      - id: set_additional_variables
        run: |
          echo "MODEL_PATH"="${{ env.REPOSITORY_NAME }}/model.pt" >> $GITHUB_ENV
      - id: download_model_weights
        run: gsutil cp ${{ needs.train.outputs.model_gspath }} $MODEL_PATH
      - id: build_test_push
        uses: ./.github/actions/build_test_push
        with:
          dockerhub_username: ${{ vars.DOCKERHUB_USERNAME }}
          dockerhub_password: ${{ secrets.DOCKERHUB_PASSWORD }}
          target: serving
          build_arguments: --build-arg MODEL_PATH=$MODEL_PATH

  model_upload:
    name: model_upload
    needs:
      - get_dockerhub_training_image_name
      - get_base_project_builder_sa_key
      - build_test_push_serving_image
    runs-on: ubuntu-latest
    if: ${{ (inputs.do_post_deployment == 'true' || inputs.do_post_deployment == '') && !failure() }}
    defaults:
      run:
        working-directory: ${{ env.REPOSITORY_NAME }}
    container:
      image: ${{needs.get_dockerhub_training_image_name.outputs.value}}
      credentials:
        username: ${{ vars.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_PASSWORD }}
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/set_variables_gcloud_auth
        with:
          credentials_json: ${{ needs.get_base_project_builder_sa_key.outputs.value }}
          env_file_artifact_name: ${{ inputs.env_file_artifact_name }}
      - id: model_upload
        run: python -m object_detection.cli --actions model_upload
        env:
          SERVING_IMAGE_NAME: ${{ needs.build_test_push_serving_image.outputs.gcp_serving_image_name }}

  deploy_test_serving:
    name: deploy_test_serving
    needs:
      - model_upload
      - get_dockerhub_training_image_name
      - get_base_project_builder_sa_key
    runs-on: ubuntu-latest
    if: ${{ inputs.model_instantiator_url != '' && (inputs.do_post_deployment == 'true' || inputs.do_post_deployment == '') && !failure() }}
    defaults:
      run:
        working-directory: ${{ env.REPOSITORY_NAME }}
    container:
      image: ${{needs.get_dockerhub_training_image_name.outputs.value}}
      credentials:
        username: ${{ vars.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_PASSWORD }}
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/set_variables_gcloud_auth
        with:
          credentials_json: ${{ needs.get_base_project_builder_sa_key.outputs.value }}
          env_file_artifact_name: ${{ inputs.env_file_artifact_name }}
      - id: deploy
        run: python -m object_detection.cli --actions deploy
        env:
          MODEL_INSTANTIATOR_HOST: ${{ inputs.model_instantiator_url }}
      - id: remove_last_model_version_if_deploy_has_failed
        if: ${{ failure() && steps.deploy.conclusion == 'failure' }}
        run: python -m object_detection.cli --actions remove_last_model_version
      - id: test_integration
        run: |
          poetry check && poetry install --with dev
          poetry run pytest -x tests/integration_tests -vv
        env:
          MODEL_INSTANTIATOR_HOST: ${{ inputs.model_instantiator_url }}
      - id: undeploy_and_remove_last_model_version_and_redeploy_if_test_integration_has_failed
        if: ${{ failure() && steps.test_integration.conclusion == 'failure' }}
        run: python -m object_detection.cli --actions undeploy remove_last_model_version deploy
